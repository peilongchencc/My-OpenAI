# Similarity Search with Milvus and OpenAI:

ä½¿ç”¨ Milvus å’Œ OpenAI è¿›è¡Œç›¸ä¼¼æ€§æœç´¢<br>

This page discusses vector database integration with OpenAI's embedding API.<br>

æœ¬é¡µé¢è®¨è®ºäº†å‘é‡æ•°æ®åº“ä¸ OpenAI embedding API çš„é›†æˆã€‚<br>

We'll showcase how [OpenAI's Embedding API](https://platform.openai.com/docs/guides/embeddings) can be used with our vector database to search across book titles.<br>

æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åˆ©ç”¨ OpenAI çš„ Embedding API ä¸æˆ‘ä»¬çš„å‘é‡æ•°æ®åº“ä¸€èµ·æœç´¢ä¹¦ç±æ ‡é¢˜ã€‚<br>

Many existing book search solutions (such as those used by public libraries, for example) rely on keyword matching rather than a semantic understanding of what the title is actually about.<br>

è®¸å¤šç°æœ‰çš„ä¹¦ç±æœç´¢è§£å†³æ–¹æ¡ˆï¼ˆä¾‹å¦‚å…¬å…±å›¾ä¹¦é¦†ä½¿ç”¨çš„é‚£äº›ï¼‰ä¾èµ–äº **å…³é”®è¯åŒ¹é…** ğŸš¨ï¼Œè€Œä¸æ˜¯å¯¹æ ‡é¢˜å®é™…å«ä¹‰çš„è¯­ä¹‰ç†è§£ã€‚<br>

Using a trained model to represent the input data is known as semantic search, and can be expanded to a variety of different text-based use cases, including anomaly detection and document search.<br>

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æ¥è¡¨ç¤ºè¾“å…¥æ•°æ®è¢«ç§°ä¸º **è¯­ä¹‰æœç´¢** âœ…ï¼Œå¯ä»¥æ‰©å±•åˆ°å„ç§ä¸åŒçš„åŸºäºæ–‡æœ¬çš„ç”¨ä¾‹ï¼ŒåŒ…æ‹¬å¼‚å¸¸æ£€æµ‹å’Œæ–‡æ¡£æœç´¢ã€‚<br>


## Getting started:

The only prerequisite you'll need here is an API key from the OpenAI website.<br>

è¿™é‡Œå”¯ä¸€éœ€è¦çš„å‰ææ˜¯ä» OpenAI ç½‘ç«™è·å–ä¸€ä¸ª API å¯†é’¥ã€‚<br>

Be sure you have already started up a Milvus instance.<br>

è¯·ç¡®ä¿æ‚¨å·²ç»å¯åŠ¨äº† Milvus å®ä¾‹ã€‚<br>

We'll also prepare the data that we're going to use for this example. You can grab the book titles [here](https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks?resource=download).<br>

æˆ‘ä»¬è¿˜ä¼šå‡†å¤‡å¥½è¿™ä¸ªä¾‹å­ä¸­è¦ä½¿ç”¨çš„æ•°æ®ï¼Œæ‚¨å¯ä»¥åœ¨è¿™é‡Œè·å–ä¹¦åã€‚<br>

Let's create a function to load book titles from our CSV. <br>

æˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ªå‡½æ•°ï¼Œä»æˆ‘ä»¬çš„ CSV æ–‡ä»¶åŠ è½½ä¹¦åã€‚<br>

```python
import csv
import json
import random
import time
from openai import OpenAI
from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection, utility
```

```python
def csv_load(file):
    with open(file, newline='') as f:
        reader=csv.reader(f, delimiter=',')
        for row in reader:
            yield row[1]
```

With this, we're ready to move on to generating embeddings. <br>

æœ‰äº†è¿™ä¸ªï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½å¼€å§‹ç”ŸæˆåµŒå…¥å‘é‡äº†ã€‚<br>


## Searching book titles with OpenAI & Milvus(ä½¿ç”¨OpenAIå’ŒMilvusæœç´¢ä¹¦å):

Here we can find the main parameters that need to be modified for running with your own accounts.<br>

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°éœ€è¦ä¿®æ”¹ä»¥é€‚åº”æ‚¨è‡ªå·±å¸æˆ·çš„ä¸»è¦å‚æ•°ã€‚<br>

Beside each is a description of what it is.<br>

æ¯ä¸ªå‚æ•°æ—è¾¹éƒ½æœ‰å…¶æè¿°ã€‚<br>

```python
FILE = './content/books.csv'  # Download it from https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks and save it in the folder that holds your script.
COLLECTION_NAME = 'title_db'  # Collection name
DIMENSION = 1536  # Embeddings size
COUNT = 100  # How many titles to embed and insert.
MILVUS_HOST = 'localhost'  # Milvus server URI
MILVUS_PORT = '19530'
OPENAI_ENGINE = 'text-embedding-3-small'  # Which engine to use, you can change it into `text-embedding-3-large` or `text-embedding-ada-002`
client = OpenAI()
client.api_key = 'sk-******'  # Use your own Open AI API Key here
```

```log
Note(æ³¨æ„):

Because the embedding process for a free OpenAI account is relatively time-consuming, we use a set of data small enough to reach a balance between the script executing time and the precision of the search results.

ç”±äºå…è´¹OpenAIå¸æˆ·çš„åµŒå…¥è¿‡ç¨‹ç›¸å¯¹è€—æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†è¶³å¤Ÿå°çš„æ•°æ®é›†æ¥åœ¨è„šæœ¬æ‰§è¡Œæ—¶é—´å’Œæœç´¢ç»“æœç²¾åº¦ä¹‹é—´è¾¾åˆ°å¹³è¡¡ã€‚

You can change the COUNT constant to fit your needs.

æ‚¨å¯ä»¥æ›´æ”¹COUNTå¸¸é‡ä»¥æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚
```

This segment deals with Milvus and setting up the database for this use case.<br>

è¿™ä¸€éƒ¨åˆ†æ¶‰åŠMilvusä»¥åŠä¸ºæ­¤ç”¨ä¾‹è®¾ç½®æ•°æ®åº“ã€‚<br>

Within Milvus, we need to set up a collection and index the collection.<br>

åœ¨Milvusä¸­ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®ä¸€ä¸ªé›†åˆå¹¶å¯¹è¯¥é›†åˆè¿›è¡Œç´¢å¼•ã€‚<br>

For more information on how to use Milvus, look [here](https://milvus.io/docs/quickstart.md).<br>

æƒ³è¦äº†è§£æ›´å¤šå…³äºå¦‚ä½•ä½¿ç”¨Milvusçš„ä¿¡æ¯ï¼Œè¯·çœ‹è¿™é‡Œã€‚<br>

```python
connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)

if utility.has_collection(COLLECTION_NAME):
    utility.drop_collection(COLLECTION_NAME)

fields = [
    FieldSchema(name='id', dtype=DataType.INT64, descrition='Ids', is_primary=True, auto_id=False),
    FieldSchema(name='title', dtype=DataType.VARCHAR, description='Title texts', max_length=200),
    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=DIMENSION)
]
schema = CollectionSchema(fields=fields, description='Title collection')
collection = Collection(name=COLLECTION_NAME, schema=schema)

index_params = {
    'index_type': 'IVF_FLAT',
    'metric_type': 'L2',
    'params': {'nlist': 1024}
}
collection.create_index(field_name="embedding", index_params=index_params)
```

Once we have the collection setup we need to start inserting our data.<br>

ä¸€æ—¦æˆ‘ä»¬è®¾ç½®å¥½äº†é›†åˆï¼Œæˆ‘ä»¬å°±éœ€è¦å¼€å§‹æ’å…¥æˆ‘ä»¬çš„æ•°æ®ã€‚<br>

This is in three steps: reading the data, embedding the titles, and inserting into Milvus.<br>

è¿™å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªæ­¥éª¤ï¼šè¯»å–æ•°æ®ï¼Œå¯¹æ ‡é¢˜è¿›è¡ŒåµŒå…¥ï¼Œç„¶åæ’å…¥åˆ°Milvusä¸­ã€‚<br>

```python
def embed(text):
    response = client.embeddings.create(
        input=text,
        model=OPENAI_ENGINE
    )
    return response.data[0].embedding

for idx, text in enumerate(random.sample(sorted(csv_load(FILE)), k=COUNT)):  # Load COUNT amount of random values from dataset
    ins=[[idx], [(text[:198] + '..') if len(text) > 200 else text], [embed(text)]]  # Insert the title id, the title text, and the title embedding vector
    collection.insert(ins)
    time.sleep(3)  # Free OpenAI account limited to 60 RPM
```

```python
collection.load()

def search(text):
    # Search parameters for the index
    search_params={
        "metric_type": "L2"
    }

    results=collection.search(
        data=[embed(text)],  # Embeded search value
        anns_field="embedding",  # Search across embeddings
        param=search_params,
        limit=5,  # Limit to five results per search
        output_fields=['title']  # Include title field in result
    )

    ret=[]
    for hit in results[0]:
        row=[]
        row.extend([hit.id, hit.score, hit.entity.get('title')])  # Get the id, distance, and title for the results
        ret.append(row)
    return ret

search_terms=['self-improvement', 'landscape']

for x in search_terms:
    print('Search term:', x)
    for result in search(x):
        print(result)
    print()
```

You should see the following as the output:<br>

æ‚¨åº”è¯¥ä¼šçœ‹åˆ°ä»¥ä¸‹å†…å®¹ä½œä¸ºè¾“å‡ºï¼š<br>

```log
Search term: self-improvement
[46, 0.37948882579803467, 'The Road Less Traveled: A New Psychology of Love  Traditional Values  and Spiritual Growth']
[24, 0.39301538467407227, 'The Leader In You: How to Win Friends  Influence People and Succeed in a Changing World']
[35, 0.4081816077232361, 'Think and Grow Rich: The Landmark Bestseller Now Revised and Updated for the 21st Century']
[93, 0.4174671173095703, 'Great Expectations']
[10, 0.41889268159866333, 'Nicomachean Ethics']

Search term: landscape
[49, 0.3966977894306183, 'Traveller']
[20, 0.41044068336486816, 'A Parchment of Leaves']
[40, 0.4179283380508423, 'The Illustrated Garden Book: A New Anthology']
[97, 0.42227691411972046, 'Monsoon Summer']
[70, 0.42461898922920227, 'Frankenstein']
```