# Embedding

OpenAI Embedding模型调用示例。
- [Embedding](#embedding)
  - [文件简介:](#文件简介)
  - [一些思考:](#一些思考)

## 文件简介:

| 文件名                           | 作用                                   | 备注    |
|---------------------------------|---------------------------------------|---------|
| get_embedding_dimensions.py     | openai词向量获取示例                     |        |
| reduce_embedding_dimensions.py  | openai词向量获取、降维示例                |        |

## 一些思考:

关于"`text-embedding-3-large` 词向量缩短到256的大小，而仍然比未缩短的text-embedding-ada-002嵌入向量（大小为1536）表现得更好"的一些思考:

推测OpenAI采用了一些特殊手段，将关键信息集中在了词向量维度的前半部分，所以在词向量降维的时候才会强行截取前n维度。

词向量维度为1563，也就是1563个特征，但每个特征含有的信息量并不均衡。假设OpenAI将80%的信息量集中在了前200的维度，**"`text-embedding-3-large` 词向量缩短到256的大小，而仍然比未缩短的text-embedding-ada-002嵌入向量（大小为1536）表现得更好"** 就可以得到合理的解释。

另外，我们一般降维采用的都是在模型结构后面**加一个全连接层**，但由于OpenAI并未开放模型代码，所以这种方式是无法实现的。